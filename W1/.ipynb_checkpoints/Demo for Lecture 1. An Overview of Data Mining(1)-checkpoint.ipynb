{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Jupyter\n",
    "This is an example of markdown text. The number of \"#\" determines the level of narrative texts. \n",
    "\n",
    "demo: $\\sum_i$, <b>text in bold\n",
    "\n",
    "# first level.\n",
    "## second level.\n",
    "### third level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Running your first program below.\n",
    "We are testing how python works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a comment in Python. You can run this cell by pressing \"Shift + Enter\" \n",
    "1+2+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review some data structures in Python: List, String, and Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [1,2,3,4,5]\n",
    "str_list = ['abc','9news','yahoo9']\n",
    "students = {'s12345':'John', 's23456':'Mary','s54321':'Jeff'}\n",
    "# print the entire data\n",
    "print(num_list)\n",
    "print(str_list)\n",
    "print(students)\n",
    "# print the items in each different data structure.\n",
    "print(num_list[0],num_list[-1])\n",
    "print(str_list[0:2])\n",
    "print(students['s23456'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to run some code samples to introduce the main topics covered in this course. If you are not familiar with Python libraries, such as pandas, scikit, and matplotlib, please read some quick tutorials. <br>\n",
    "10 minutes to Pandas: http://pandas.pydata.org/pandas-docs/stable/10min.html <br>\n",
    "scikit manual:<br>\n",
    "matplotlib:<br>\n",
    "Bank Data: https://archive.ics.uci.edu/ml/datasets/bank+marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Main topics covered in this course</b>:<br>\n",
    "<li>Explore Data and Pre-process Data</li>\n",
    "<li>Data Warehouse and OLAP</li>\n",
    "<li>Mining Frequent Patterns</li>\n",
    "<li>Machine Learning in Data Mining</li>\n",
    "<li>Outlier Detection</li>\n",
    "<li>Time Series and Sequential Data Mining</li>\n",
    "<li>Text Database Mining</li>\n",
    "<li>World-Wide-Web Mining</li>\n",
    "<li>Data Mining on Information Networks</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Mining with Python and its amazing libraries.\n",
    "## 2.1. Reading and Display Data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "#df = pd.read_csv(\"./bank.csv\")\n",
    "df = pd.read_csv(\"./bank.csv\",delimiter=\";\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. You can summarise the numerical features by using describe() function in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. We can use value_counts() function to have a look at a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can have good visual results from data itself, we can use some visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist = df['age'].hist(bins=100)\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot = df.boxplot(column='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the histogram, we can use box plot, which reflects more about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this follow figure, max, min, median values of age in different groups will be drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot1 = df.boxplot(column='age', by = 'marital', showfliers=False)\n",
    "# you can show outliers in the figure or not to show outliers\n",
    "plt.boxplot2 = df.boxplot(column='age', by = 'education', showfliers=False)\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the missing data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: sum(x.isnull()),axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = pd.read_csv(\"./admissions.csv\")\n",
    "df_med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med.apply(lambda x: sum(x.isnull()),axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are quite missing values in columns deathtime, language, etc. In our course, we will discuss how we can deal with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictive Models in Data Mining.\n",
    "## Let's build predictive models to classify the bank data.\n",
    "To predict if the client subscribed a term deposit? (Y or N) -- a typcial binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "\n",
    "print(sklearn.__version__)\n",
    "\n",
    "for col_name in df.columns:\n",
    "    if(df[col_name].dtype=='object'):\n",
    "        df[col_name] = df[col_name].astype('category')\n",
    "        df[col_name] = df[col_name].cat.codes\n",
    "\n",
    "X1 = np.array(df.values[:,0:9])\n",
    "X2 = np.array(df.values[:,11:-1])\n",
    "X = np.concatenate((X1,X2), axis=1)\n",
    "\n",
    "y = np.array(df.values[:,-1])\n",
    "print(len(df['job'].unique()),len(df['marital'].unique()),len(df['education'].unique()),len(df['default'].unique()),len(df['housing'].unique()),len(df['loan'].unique()),len(df['contact'].unique()),len(df['poutcome'].unique()))\n",
    "\n",
    "\n",
    "#enc = OneHotEncoder(n_values = [12, 3, 4, 2, 2, 2, 3, 4], categorical_features=[1, 2, 3, 4, 6, 7, 8, 13])\n",
    "#X = enc.fit_transform(X).toarray()\n",
    "\n",
    "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(),[1, 2, 3, 4, 6, 7, 8, 13])], remainder=\"passthrough\")\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "print(X.shape)\n",
    "print(X[0,:])\n",
    "X_n = minmax_scale(X)\n",
    "print(X_n)\n",
    "\n",
    "\n",
    "liblinear_params = {'C':[0.1,1,10,100 ] }     # Linear SVC\n",
    "dtree_params = {'max_depth':[5,10,15] }    # Decision Tree classifier\n",
    "knn_params = {'n_neighbors': [1, 5, 10, 15]}     # KNN (K Nearest Neighbors classifier)\n",
    "\n",
    "\n",
    "X_tr, X_te, ys_tr, ys_te = train_test_split( X_n, y, test_size = 0.3)\n",
    "#max_iter=10000000\n",
    "liblinear = LinearSVC(dual=False)\n",
    "clf = GridSearchCV(liblinear, liblinear_params, cv =2, n_jobs =1, verbose =1)\n",
    "clf.fit(X_tr, ys_tr)\n",
    "liblinear_pred = clf.predict(X_te)\n",
    "accuracy = accuracy_score(ys_te, liblinear_pred)\n",
    "print(\"Liblinear-> The best parameter is %.3f Accuracy: %.6f\"%(clf.best_params_['C'],accuracy))\n",
    "    \n",
    "dtree = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dtree, dtree_params, cv =2, n_jobs =1, verbose =1)\n",
    "clf.fit(X_tr, ys_tr)\n",
    "dtree_pred = clf.predict(X_te)\n",
    "accuracy = accuracy_score(ys_te, dtree_pred)\n",
    "print(\"Decision Tree-> The best parameter is %.3f Accuracy: %.6f\"%(clf.best_params_['max_depth'],accuracy)) \n",
    "        \n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn, knn_params, cv =2, n_jobs =1, verbose =3)\n",
    "clf.fit(X_tr, ys_tr)\n",
    "knn_pred = clf.predict(X_te)\n",
    "accuracy = accuracy_score(ys_te, knn_pred)\n",
    "print(\"KNN -> The best parameter is %.3f Accuracy: %.6f\"%(clf.best_params_['n_neighbors'],accuracy)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see accuracies of Linear SVM, Decision Tree, and KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. An Example of Association Rule Mining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "print(mlxtend.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda config --add channels conda-forge            \n",
    "#conda install mlxtend\n",
    "#the above two lines are for install the module: mlxtend\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "#http://pbpython.com/market-basket-analysis.html\n",
    "df = pd.read_csv(\"./sales.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing data: remove white-spaces in descriptions, and drop rows without invoice number, and remove cedit transactions\n",
    "df['Description'] = df['Description'].str.strip()\n",
    "df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
    "df = df[~df['InvoiceNo'].str.contains('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Country'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As the dataset stores transaction records, we need to extract how many items purchased in each one transaction by using a Bag-of-Word vector, each of which represents the quantity of the item for each transaction. In this example code, we only use records from France and Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket = (df[df['Country'] ==\"France\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "basket_sets.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the tricky part is figuring out what this tells us. For instance, we can see that there are quite a few rules with a high lift value, which means that it occurs more frequently than would be expected, given the number of transactions and product combinations. We can also see several where the confidence is high as well. This part of the analysis is where the domain knowledge will come in handy. Since I do not have that, Iâ€™ll just look for a couple of illustrative examples.\n",
    "\n",
    "We can filter the dataframe using standard pandas code. In this case, look for a high confidence (.9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[ rules['confidence'] >= 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we can observe that these stuff would be purchases together most frequently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
